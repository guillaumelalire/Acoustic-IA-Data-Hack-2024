{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/opt/mamba/lib/python3.11/site-packages/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZN3c104cuda9SetDeviceEi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/Acoustic-IA-Data-Hack-2024/vggish_pytorch.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://user-guillaumelalire-352178-0.user.lab.sspcloud.fr/home/onyxia/work/Acoustic-IA-Data-Hack-2024/vggish_pytorch.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchaudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://user-guillaumelalire-352178-0.user.lab.sspcloud.fr/home/onyxia/work/Acoustic-IA-Data-Hack-2024/vggish_pytorch.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://user-guillaumelalire-352178-0.user.lab.sspcloud.fr/home/onyxia/work/Acoustic-IA-Data-Hack-2024/vggish_pytorch.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torchaudio/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Initialize extension and backend first\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _extension  \u001b[39m# noqa  # usort: skip\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa  # usort: skip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     AudioMetaData,\n\u001b[1;32m      5\u001b[0m     get_audio_backend,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     set_audio_backend,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     compliance,\n\u001b[1;32m     15\u001b[0m     datasets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     utils,\n\u001b[1;32m     24\u001b[0m )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torchaudio/_extension/__init__.py:38\u001b[0m\n\u001b[1;32m     36\u001b[0m _IS_ALIGN_AVAILABLE \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m _IS_TORCHAUDIO_EXT_AVAILABLE:\n\u001b[0;32m---> 38\u001b[0m     _load_lib(\u001b[39m\"\u001b[39;49m\u001b[39mlibtorchaudio\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     40\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorchaudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_torchaudio\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     _check_cuda_version()\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torchaudio/_extension/utils.py:60\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mload_library(path)\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/torch/_ops.py:1032\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1027\u001b[0m path \u001b[39m=\u001b[39m _utils_internal\u001b[39m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1028\u001b[0m \u001b[39mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1029\u001b[0m     \u001b[39m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m     \u001b[39m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m     \u001b[39m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m     ctypes\u001b[39m.\u001b[39;49mCDLL(path)\n\u001b[1;32m   1033\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloaded_libraries\u001b[39m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/ctypes/__init__.py:376\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    377\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /opt/mamba/lib/python3.11/site-packages/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZN3c104cuda9SetDeviceEi"
     ]
    }
   ],
   "source": [
    "import torchaudio.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "from models import CustomVGGish2\n",
    "\n",
    "deconv = np.load('../Acoustic-IA-Data-Hack-2024/data/LivingRoom_preprocessed_hack/Human1/deconvoled_trim.npy')\n",
    "centroid = np.load('../Acoustic-IA-Data-Hack-2024/data/LivingRoom_preprocessed_hack/Human1/centroid.npy')\n",
    "\n",
    "train_xy = centroid[200:]\n",
    "valid_xy = centroid[100:200]\n",
    "test_xy = centroid[:100]\n",
    "\n",
    "train_mean = np.mean(train_xy, axis=0)\n",
    "train_std = np.std(train_xy, axis=0)\n",
    "\n",
    "train_xy = (train_xy - train_mean) / (train_std + 1e-8)\n",
    "valid_xy = (valid_xy - train_mean) / (train_std + 1e-8)\n",
    "test_xy =  (test_xy - train_mean) / (train_std + 1e-8)\n",
    "\n",
    "train_waves = deconv[200:, :]\n",
    "# 30950 seems to be the rough cutoff after which vggish treats the input as two examples.\n",
    "valid_waves = deconv[100:200, :]\n",
    "#Test Waves\n",
    "test_waves = deconv[:100, :]\n",
    "\n",
    "precutoff = 92850\n",
    "\n",
    "train_waves = train_waves[..., :precutoff]\n",
    "valid_waves = valid_waves[..., :precutoff]\n",
    "test_waves = test_waves[..., :precutoff]\n",
    "\n",
    "train_waves = torch.Tensor(train_waves).cuda()\n",
    "train_xy = torch.Tensor(train_xy).cuda()\n",
    "\n",
    "valid_waves = torch.Tensor(valid_waves).cuda()\n",
    "valid_xy = torch.Tensor(valid_xy).cuda()\n",
    "\n",
    "test_waves = torch.Tensor(test_waves).cuda()\n",
    "test_xy = torch.Tensor(test_xy).cuda()\n",
    "\n",
    "def resample(audio, ir=48000, tr=16000):\n",
    "    resampled_waveform = F.resample(\n",
    "        audio,\n",
    "        ir,\n",
    "        tr,\n",
    "        lowpass_filter_width=64,\n",
    "        rolloff=0.9475937167399596,\n",
    "        resampling_method=\"kaiser_window\",\n",
    "        beta=14.769656459379492,\n",
    "    )\n",
    "    return resampled_waveform\n",
    "\n",
    "print(\"Resampling\")\n",
    "train_waves = resample(train_waves)\n",
    "valid_waves = resample(valid_waves)\n",
    "test_waves = resample(test_waves)\n",
    "\n",
    "vggish_cutoff = 15475\n",
    "\n",
    "train_waves = train_waves[..., :vggish_cutoff]\n",
    "valid_waves = valid_waves[..., :vggish_cutoff]\n",
    "test_waves = test_waves[..., :vggish_cutoff]\n",
    "\n",
    "out_channels = 2\n",
    "\n",
    "# Instantiate the CustomVGGish2 model\n",
    "net = CustomVGGish2(in_channels=4, out_channels=10)  # Adjust in_channels and out_channels according to your requirements\n",
    "\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print('Total parameters: %i'%total_params)\n",
    "print('Trainable parameters: %i'%trainable_params)\n",
    "    \n",
    "xy_loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "lr = 0.00001\n",
    "\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.999995)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "N_iter = int(train_waves.shape[0] / batch_size)\n",
    "train_losses = []\n",
    "train_xy_losses = []\n",
    "valid_losses = []\n",
    "valid_xy_losses = []\n",
    "step_count = 0\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    print('Reshuffling for Epoch %i'%n, flush=True)\n",
    "    rand_idx = np.random.permutation(train_waves.shape[0])\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(N_iter):\n",
    "        curr_idx = rand_idx[i*batch_size:(i+1)*batch_size]\n",
    "        net_out = net(train_waves[curr_idx, :])\n",
    "        results = postprocess_net_output(net_out)\n",
    "        xy_loss = xy_loss_fn(results[:, :2], train_xy[curr_idx, :2])\n",
    "        loss = xy_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss = loss.item()\n",
    "        train_losses.append((step_count, train_loss))\n",
    "        train_xy_losses.append((step_count, xy_loss.item()))\n",
    "        step_count+=1\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    net.eval()\n",
    "    valid_loss_xy_arr = np.zeros(valid_waves.shape[0], dtype=np.float32)\n",
    "    valid_loss_arr = np.zeros(valid_waves.shape[0], dtype=np.float32)\n",
    "    for i in range(valid_waves.shape[0]):\n",
    "        with torch.no_grad():\n",
    "            results = torch.squeeze(postprocess_net_output(net(torch.unsqueeze(valid_waves[i, :], axis=0)).view(-1, 1)))\n",
    "        xy_loss = xy_loss_fn(results[:2], valid_xy[i, :2])\n",
    "        valid_loss_xy_arr[i] = xy_loss.item()\n",
    "        loss = xy_loss\n",
    "        valid_loss_arr[i] = loss.item()\n",
    "    valid_xy_loss = np.mean(valid_loss_xy_arr)\n",
    "    valid_loss = np.mean(valid_loss_arr)\n",
    "    print('Validation XY Loss: %0.3f'%valid_xy_loss)\n",
    "    print('Validation Loss: %0.3f'%valid_loss)\n",
    "    valid_losses.append((step_count, valid_loss))\n",
    "    valid_xy_losses.append((step_count, valid_xy_loss))\n",
    "\n",
    "    \n",
    "    np.save(os.path.join(args.error_path, 'train_losses.npy'), np.array(train_losses, dtype=np.float32))\n",
    "    np.save(os.path.join(args.error_path, 'valid_losses.npy'), np.array(valid_losses, dtype=np.float32))\n",
    "\n",
    "    #Iterate through test\n",
    "    test_errors = np.zeros(test_waves.shape[0], dtype=np.float32)\n",
    "\n",
    "    for i in range(test_waves.shape[0]):\n",
    "        with torch.no_grad():\n",
    "            results = torch.squeeze(postprocess_net_output(net(torch.unsqueeze(test_waves[i, :], axis=0)).view(-1, 1)))\n",
    "            \n",
    "            \n",
    "        test_errors[i] = torch.norm(unnormalize(results[:2]) - unnormalize(test_xy[i, :2])).item()\n",
    "\n",
    "    print(\"TEST ERROR\")\n",
    "    print(test_errors)\n",
    "        \n",
    "    print(\"MEAN TEST ERROR\",flush=True)\n",
    "    print(np.mean(test_errors))\n",
    "    print(\"MED TEST ERROR\")\n",
    "    print(np.median(test_errors))\n",
    "    print(\"STD TEST ERROR\")\n",
    "    print(np.std(test_errors))\n",
    "\n",
    "    np.save(os.path.join(args.error_path, 'test_errors.npy'), np.array(test_errors, dtype=np.float32))        \n",
    "\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': n,\n",
    "        'model_state_dict': net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'train_xy_losses': train_xy_losses,\n",
    "        'valid_losses': valid_losses,\n",
    "        'valid_xy_losses': valid_xy_losses,\n",
    "        'train_mean': train_mean,\n",
    "        'train_std': train_std,\n",
    "        'norm_val_min':norm_val_min,\n",
    "        'norm_val_range':norm_val_range,\n",
    "        'lr': args.lr,\n",
    "    }, args.save_path)\n",
    "    \n",
    "\n",
    "\n",
    "# Prepare your input data (assuming signals_tensor is your processed input tensor)\n",
    "# Assuming signals_tensor is already reshaped and processed as needed by CustomVGGish2\n",
    "# Make sure signals_tensor is a PyTorch tensor and is on the correct device\n",
    "signals_tensor = torch.tensor(signals, dtype=torch.float32)  # Assuming signals is your numpy array of signals\n",
    "signals_tensor = signals_tensor.to(model.device)  # Ensure tensor is on the correct device\n",
    "\n",
    "# Pass the input data through the model\n",
    "output = model(signals_tensor)\n",
    "\n",
    "# Now 'output' contains the output of the CustomVGGish2 model\n",
    "# You can use this output for further processing or analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'strides'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/onyxia/work/Acoustic-IA-Data-Hack-2024/vggish_pytorch.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://user-guillaumelalire-352178-0.user.lab.sspcloud.fr/home/onyxia/work/Acoustic-IA-Data-Hack-2024/vggish_pytorch.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_waves\u001b[39m.\u001b[39;49mstrides()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'strides'"
     ]
    }
   ],
   "source": [
    "train_waves.strides()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
